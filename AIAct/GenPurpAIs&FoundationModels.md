**Guidelines for Standard General Purpose AI under the AI Act:
The classification for a GPAI of enough power to be included in having the guidelines applicable is a model with ~1 billion parameters trained on substantial datasets.

Lifecycle-wide obligations under the AI Act apply from the start of its pre-training run and extend to all subsequent development phases, including post-market modifications. 

Obligations include:
- Documentation: Must be maintained and updated, and provided to downstream providers and, upon request, to the AI Office or national competent authorities.
- Training data summary: Providers must publish a summary using the yet-to-be-issued AI Office template.
- Copyright policy: Must address copyright compliance and may apply across all models.

General Purpose AI with systemic risk: Any model trained using ≥10²⁵ FLOPS is presumed to have high-impact capabilities and may be classified as systemic-risk GPAI that has additional obligations.

The additional obligations are:
- Comprehensive risk assessment and mitigation throughout the lifecycle, including model evaluations.
- Robust cybersecurity measures
- Serious Incident tracking and reporting

***Upstream and downstream responsibility allocation
- Upstream providers:
If an upstream actor first makes the model available to any downstream actor on the EU market, that actor is the provider and must meet GPAI provider obligations. 

- Downstream system integrators:
If a downstream actor incorporates the GPAI model into an AI system and places the system on the EU market, they are a system provider and must meet obligations relevant to AI systems.

- Non-EU origin models:
If a model is made available outside the EU but is later incorporated into a system placed on the EU market, the model is considered placed at that point.
The upstream actor is the provider unless they have explicitly excluded EU use. In such cases, the downstream actor becomes the provider.